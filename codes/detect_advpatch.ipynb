{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitopenmmlabconda8b303c584c604ca99f71b49f81978ded",
   "display_name": "Python 3.7.7 64-bit ('open-mmlab': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pdb\n",
    "import torch\n",
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "from glob import glob\n",
    "from mylogger import get_mylogger\n",
    "from image_specific_attack import create_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path: str):\n",
    "    filename = glob(image_path+\"*.pth\")\n",
    "    adv_examples = []\n",
    "    labels = []\n",
    "    for file in tqdm(filename[0:1000]):\n",
    "        adv_example = torch.load(file)\n",
    "        adv_examples.append(adv_example)\n",
    "\n",
    "        label = int(re.split('_|\\.', file)[-2])\n",
    "        labels.append(label)\n",
    "\n",
    "    return adv_examples, labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=> creating model \n",
      "100%|██████████| 1000/1000 [00:08<00:00, 122.64it/s]\n"
     ]
    }
   ],
   "source": [
    "# log_path = \"./log/detect\"\n",
    "# os.makedirs(log_path, exist_ok=True)\n",
    "# logger = get_mylogger(log_path)\n",
    "\n",
    "patch_size = 7\n",
    "model = create_model(\n",
    "    'ResNet18', './result/models/ResNet18_{}/model_best.pth.tar'.format(patch_size)).eval()\n",
    "\n",
    "adv_example_path = 'result/attack/image_specific/ResNet18/ResNet18_{}/patched/'.format(\n",
    "    patch_size)\n",
    "adv_examples, labels = load_image(adv_example_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_normal_acc(model, adv_examples, labels):\n",
    "    normal_acc = 0\n",
    "    for i in trange(len(adv_examples)):\n",
    "        adv_example = adv_examples[i]\n",
    "        label = labels[i]\n",
    "\n",
    "        adv_out = F.log_softmax(model(adv_example), dim=1)\n",
    "        adv_out_probs, adv_out_labels = adv_out.max(1)\n",
    "        # have already set the target label to 5.\n",
    "        if adv_out_labels == label:\n",
    "            normal_acc += 1\n",
    "    print(\"\\nnormal acc: \", normal_acc/len(adv_examples))\n",
    "\n",
    "def compute_attack_acc(model, adv_examples, labels):\n",
    "    attack_acc = 0\n",
    "    for i in trange(len(adv_examples)):\n",
    "        adv_example = adv_examples[i]\n",
    "        label = labels[i]\n",
    "\n",
    "        adv_out = F.log_softmax(model(adv_example), dim=1)\n",
    "        adv_out_probs, adv_out_labels = adv_out.max(1)\n",
    "        # have already set the target label to 5.\n",
    "        if adv_out_labels == 5:\n",
    "            attack_acc += 1\n",
    "    print(\"\\nattack acc: \", attack_acc/len(adv_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 1000/1000 [00:02<00:00, 353.40it/s]normal acc:  0.483\n",
      "\n"
     ]
    }
   ],
   "source": [
    "compute_normal_acc(model, adv_examples, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.conv1(adv_examples[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 32, 32])"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output.sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[ 0.8805,  0.0748,  0.0301,  ...,  0.7565,  0.8731, -1.4665],\n",
       "         [ 0.5255,  3.8484,  4.9588,  ...,  3.6319,  3.7243,  1.6387],\n",
       "         [ 1.4340,  3.3534,  3.5075,  ...,  3.4980,  3.7199,  1.0239],\n",
       "         ...,\n",
       "         [ 2.6459,  2.1276,  2.6825,  ...,  2.1246,  2.2442,  0.8276],\n",
       "         [ 2.8909,  2.5445,  3.1157,  ...,  2.3924,  2.5949,  1.4347],\n",
       "         [ 2.1683,  2.1464,  2.2724,  ...,  1.2385,  0.8842,  1.5611]]],\n",
       "       device='cuda:0', grad_fn=<SumBackward1>)"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_output = output.reshape(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "topk = 115\n",
    "topk_value = tmp_output[torch.topk(tmp_output,topk)[1][-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(114., device='cuda:0', grad_fn=<SumBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "tmp_output = torch.relu(torch.sign(output-topk_value))\n",
    "tmp_output.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_one_conv = torch.nn.Conv2d(1,1,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_one_conv.weight.data = torch.ones((1,1,7,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]], device='cuda:0',\n",
       "       grad_fn=<UnsqueezeBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "source": [
    "tmp_output.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 26, 26])"
      ]
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "source": [
    "all_one_conv(tmp_output.unsqueeze(0).to(torch.device('cpu'))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}